# Network-wide Rule Orchestrator

This repository contains the code and instructions to replicate the results of the paper ()[]. 

## **Table of Contents**
- [Installation process](#installation-process)
- [Repository structure](#repository-structure)
- [Replicating the experiments](#replicating-the-experiments)
- [Obtaining the baseline alerts](#obtaining-the-baseline-alerts)
- [Evaluating new topologies](#evaluating-new-topologies)

## Installation process

### 1. Install Vagrant and VirtualBox

- [Vagrant](https://developer.hashicorp.com/vagrant/install)

- [VirtualBox](https://www.virtualbox.org/wiki/Downloads)

### 2. Build the P4 virtual machine

Clone the oficial repository:

```
git clone https://github.com/p4lang/tutorials.git
```

```
cd tutorial/vm-ubuntu-20.04
```
Run the following command:

```
vagrant up
```

### 3. Adjust the P4 VM settings

Turn off the machine, and extend the number of cores and memory size so it does not crash during the experiments.

For the experiments we used a DELL server with a significant amount of cores and memory. For the P4 VM we defined:
- 22 vCPU cores
- 146 GB of memory

We did not experiment with smaller configuration values. If using smaller configuration values, do one round of experiments and compare the number of packets processesd by the source switch. If the egress number of packets is considerably smaller than the input for any input PCAP, you need to increase the memory space or number of cores.

### 4. Log into the machine and clone this repository

```
sudo apt update && cd Documents
```

```
git clone  https://github.com/HenriqueBBrum/Network-Wide-Rule-Orchestrator.git && cd Network-Wide-Rule-Orchestrator
```

### 5. Download the CIC-IDS-2017 PCAP files and create a shared folder with the guest system

To dowload them, go to [this link](https://www.unb.ca/cic/datasets/ids-2017.html), and scroll down to the end of the page. Click the `Download this dataset` and fill in the required information. Finally, enter the `CIC-IDS-2017` directory, then the `PCAPs` directory, and download the PCAP for each day of the week. They are big PCAPs, with over 8GB of data, so they take a while to download.

Save them into your host machine in one folder. For the guest folder, it must be named `CICIDS2017-PCAPS` and placed at the same level as this repo's folder. The image below illustrates this:
<p align="center">
	<img src="./assets/guest_folder_placement.png" alt="drawing" width="800"/>
</p>


For more information on how to create shared folders with VirtualBox, follow these links:
- [How to Create and Access a Shared Folder in VirtualBox](https://www.makeuseof.com/how-to-create-virtualbox-shared-folder-access/)
- [How to create shared folder for virtual machine on VirtualBox](https://pureinfotech.com/create-shared-folder-virtual-machine-virtualbox/)


### 6. Install the dependencies

The last step is to run the follwoing command to automatically install all required dependencies and configure the enviroment:

```
./install_dependencies.sh
```

> :warning: This script takes a long time to finish, be patitent.

The packages and tools installed are the following:
- tcpreplay
- matplotlib and networkx (Python)
- BMv2 (for custom high performance)
- Snort3

After this process ends, the enviroment is configured and ready to run the experiments. 

## Repository structure

```
├── assets/
├── baseline_alerts/
├── snort/
├── src/
├── testing/
├── utils/
├── .gitignore
├── install_dependencies.sh
├── README.md
```

- **`assest/`**: The images used in this README file;

- **`baseline_alerts/`**: The alerts generated by Snort 3 when using the CIC-IDS-2017 dataset as the input traffic and the following rulesets: Snort 3 Community, Snort 2 Emerging Threats, Snort 3 Registered;

- **`snort/`**: Snort folder with the configuration files, rulesets, and the logs output;

- **`src/`**: Data plane folder with the P4 code and topologies definition;
	- **`include/`**: Folder with files defining the P4 headers and the P4 parser;
	- **`topologies/`**: This folder contains the topologies used in the experiments, with the topology definitons and fowarding for the swtiches;
	- **`main.p4`**: Main P4 file, detailing the functioning of the data plane;
	- **`p4_table_entries*.config`**: The table entries to offload;

- **`testing/`**: The testing and plotting files;
	- **`dataplane_parameters_evaluation.json`**: The testing and plotting files for the dataplane parameters evaluation where the dataplane algorithms parameters are evaluated;
	- **`experiment_configuration.json`**: The configuration files for each topology. These files contanin configurations for the table entries offloading programa and the experiemnts's Mininet nodes;
	- **`final_evaluation.json`**: The testing and plotting files for the final evaluation with different offloading algorithms and topologies;

- **`utils/`**: Folder containing Python files that interact with Mininet and the P4Runtime;
	- **`offload_table_entries.py`**: File responsbile for offloading the table entries to the swtiches according to the offloading algorithm;
	- **`default.json`**: Python file responsible for creatin the Mininet enviroment and running an experiment;

- **`.gitignore`**: Files for git to ignore;

- **`/install_dependencies.sh`**: Script used in to install the depedencies and to configure the environment;

- **`/README.md`**: README file with this project's documentation.


## Replicating the experiments

There are two set of experiments to replicate: the [data plane parameters evaluation](#data-plane-parameters-experiments), and the [final evaluation](final-evaluation). The first evaluates different data plane configurations to decide on the best one. The latter evalautes the network-wide offloading algorithms with two topology scenarios, linear and tree, using different memory availability in the switches.

### Data plane parameters evaluation

The data plane parameters evaluations evaluates three parameters:
- The number of packest to clone for each count-min entry, or _N_.
	- The values testes are: 10, 25, 50, 100, 200, 400, 800
- The time threshold to age the count-min entries, or _T_.
	- The values testes are: 10, 25, 50.
- The width of the count-min sketch hash arrays, or _W_.
	- The values testes are: 256, 512, 1024, 4096, 16834.

> The evaluation experiments with all combinations of the three parameteres

Before running the experiment, there is the need to do some adjustments in the code. First, uncomment the following line in the `utils/`:

```
print("Installed P4 Program using SetForwardingPipelineConfig on switch "+switch_id)
switch.SetForwardingPipelineConfig(p4info=p4info_helper.p4info, bmv2_json_file_path=bmv2_json)
```
In the data plane paremeters evaluation, the topology used does not have fowarding rules; it only clones suspicous packets and send the packets to a default port. Because of this, the P4 program is not yet installed in the data plane. To better understand the difference, compare the `switches` json object in the `src/topologies/parameters_eval/topology.json` file with the one in the `src/linear/parameters_eval/topology.json` file. Since the `parameters_eval` topology does not have the `runtime_json" : "topologies/linear/s*-runtime.json"` entry, no fowarding rules are offloaded to the switch, causing the P4 program to not being loaded during the Mininet node creation. SUmmarizing, the switch in the this evaluation is a blank switch. 

Second, uncommet the follwing line in the `src/main.p4` to foward packets to the default port:

```
standard_metadata.egress_spec = DEFAULT_PORT;
```

Lastly, comment (//) the following line in the `src/main.p4` since there are no IPv4 fowarding rules in the siwtche of this experriment:
 ```
ipv4_lpm.apply();
```

With this changes done, create an output folder in any location you like, for example:

```
mkdir ~/Documents/dataplane_parameters_evaluation
```

And run the following command on the terminal:

```
./evaluate_parameters ~/Documents/dataplane_parameters_evaluation
```

> Always inform the fullpath, not realtive path, to the output folder.

This whole evaluation takes a LONG time. There are roughly 55 million packets being sent at a rate of 1000 packest/s (due to BMv2 limited perfromance), which traslate to 15 hours to evaluate each parameters. There are 105 combiantions, so...it is a VERY LONG TIME. If you wish to reduce the number of parameters to evaluate feel free to do it.

After finishin the experimnets, it is time to graph them. For this, install jupyter:

```
pip install jupyterlab
```

And run in the `testing` folder the command:

```
jupyter lab --NotebookApp.iopub_data_rate_limit=1.0e10
```

Before running the notebook, update the experiments input folder and the output folder in the `Parse the parameters evaluation experiments` code. 
> Change the output folder so it does not collides with the graphs of this repostory.

With the folders updated, strat the kernl and run all cells to plot the graphs.


### Final evaluation


### Run individual experiments


## Obtaining the baseline alerts

The baseline alerts used to compare against the experiments alerts were obtained through the following method:

```
snort -c snort.lua --rule-path <rule-path> -R <pcap-file> -A alert_json --lua "alert_json = {file = true}"
```

This command runs Snort 3 with a ruleset as input and an input PCAP. The input rulesets are in the `snort/rules` folder. The ouput alerts file is save


## Evaluating new topologies
